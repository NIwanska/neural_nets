{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import DatasetFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natalia/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "trainset = ImageFolder(\"train/\", transform=transform)\n",
    "\n",
    "# Określenie proporcji podziału (np. 80% danych treningowych, 20% danych testowych)\n",
    "train_size = int(0.8 * len(trainset))\n",
    "test_size = len(trainset) - train_size\n",
    "\n",
    "# Podział trainset na zbiory treningowy i testowy\n",
    "train_dataset, test_dataset = random_split(trainset, [train_size, test_size])\n",
    "\n",
    "# Utworzenie DataLoader dla każdego zbioru danych\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=16)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                           shuffle=False, num_workers=16)\n",
    "\n",
    "\n",
    "# test_dataset = ImageFolder('test_all', transform=transform)\n",
    "\n",
    "# test_all_set = DatasetFolder(\"test_all/\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=transform)\n",
    "\n",
    "\n",
    "# test_all_loader = torch.utils.data.DataLoader(test_all_set, batch_size=batch_size,\n",
    "#                                          shuffle=False, num_workers=16)\n",
    "\n",
    "\n",
    "classes = trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## Warstwa konwolucyjna\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        ## Warstwa max pooling \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Poprawka na max pooling\n",
    "        self.fc1 = nn.Linear(16 * 13 * 13, 120)  # 16 * 13 * 13 zamiast 16 * 5 * 5\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)\n",
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images[0:1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] loss: 3.375\n",
      "[2/5] loss: 2.856\n",
      "[3/5] loss: 2.611\n",
      "[4/5] loss: 2.451\n",
      "[5/5] loss: 2.330\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('[%d/5] loss: %.3f' %\n",
    "          (epoch+1 ,  running_loss / 2000))\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 34 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = net(images).cpu()\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class acoustic is: 16.6 %\n",
      "Accuracy for class antenna is: 39.0 %\n",
      "Accuracy for class bacteria is: 34.6 %\n",
      "Accuracy for class battery is: 29.3 %\n",
      "Accuracy for class bean  is: 40.0 %\n",
      "Accuracy for class beetle is: 54.6 %\n",
      "Accuracy for class bicycle is: 40.5 %\n",
      "Accuracy for class birch is: 13.7 %\n",
      "Accuracy for class bird  is: 9.3 %\n",
      "Accuracy for class bomb  is: 35.0 %\n",
      "Accuracy for class bread is: 23.9 %\n",
      "Accuracy for class bridge is: 36.5 %\n",
      "Accuracy for class camera is: 33.6 %\n",
      "Accuracy for class carbon is: 0.0 %\n",
      "Accuracy for class cat   is: 22.7 %\n",
      "Accuracy for class corn  is: 11.9 %\n",
      "Accuracy for class crab  is: 14.6 %\n",
      "Accuracy for class crocodilian is: 31.1 %\n",
      "Accuracy for class echinoderm is: 20.5 %\n",
      "Accuracy for class egg   is: 20.9 %\n",
      "Accuracy for class elephant is: 22.5 %\n",
      "Accuracy for class fish  is: 44.8 %\n",
      "Accuracy for class flower is: 82.4 %\n",
      "Accuracy for class frog  is: 19.1 %\n",
      "Accuracy for class fungus is: 59.7 %\n",
      "Accuracy for class gauge is: 42.7 %\n",
      "Accuracy for class hammer is: 69.2 %\n",
      "Accuracy for class icecream is: 26.2 %\n",
      "Accuracy for class kangaroo is: 28.3 %\n",
      "Accuracy for class memorial is: 47.7 %\n",
      "Accuracy for class monkey is: 45.7 %\n",
      "Accuracy for class motor is: 44.7 %\n",
      "Accuracy for class nest  is: 11.2 %\n",
      "Accuracy for class palm  is: 48.8 %\n",
      "Accuracy for class pizza is: 67.8 %\n",
      "Accuracy for class pot   is: 23.7 %\n",
      "Accuracy for class printer is: 35.4 %\n",
      "Accuracy for class saw   is: 52.2 %\n",
      "Accuracy for class snake is: 10.3 %\n",
      "Accuracy for class spice is: 38.3 %\n",
      "Accuracy for class spider is: 36.5 %\n",
      "Accuracy for class spoon is: 52.3 %\n",
      "Accuracy for class squash is: 31.4 %\n",
      "Accuracy for class swine is: 33.0 %\n",
      "Accuracy for class tea   is: 26.5 %\n",
      "Accuracy for class tomato is: 60.5 %\n",
      "Accuracy for class towel is: 27.4 %\n",
      "Accuracy for class truck is: 59.4 %\n",
      "Accuracy for class turtle is: 16.0 %\n",
      "Accuracy for class worm  is: 9.9 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data    \n",
    "        images = images.to(device)\n",
    "        outputs = net(images).cpu()   \n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "  \n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, \n",
    "                                                   accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
